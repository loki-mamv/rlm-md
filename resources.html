<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Resources -- Papers, Code, and Tools | rlm.md</title>
    <meta name="description" content="Essential resources for Recursive Language Models: the arXiv paper, GitHub repository, pip package, sandbox options, Google ADK integration, and related work on long-context processing.">
    <meta name="keywords" content="RLM resources, recursive language models code, rlms pip package, RLM GitHub, Google ADK RLM, long context papers">
    <link rel="canonical" href="https://rlm.md/resources.html">
    <meta property="og:title" content="Resources -- Papers, Code, and Tools">
    <meta property="og:description" content="Everything you need to start using Recursive Language Models: paper, code, pip package, and related work.">
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 32 32'%3E%3Ctext x='16' y='24' font-family='monospace' font-weight='800' font-size='14' fill='%23c9a84c' text-anchor='middle'%3Erlm%3C/text%3E%3C/svg%3E">
    <link rel="stylesheet" href="style.css">
</head>
<body>

<nav class="site-nav">
    <a href="index.html" class="site-logo">rlm<span class="dot">.md</span></a>
    <button class="nav-toggle" onclick="document.querySelector('.nav-links').classList.toggle('open')" aria-label="Menu">///</button>
    <ul class="nav-links">
        <li><a href="./">Home</a></li>
        <li><a href="fundamentals.html">Fundamentals</a></li>
        <li><a href="techniques.html">Techniques</a></li>
        <li><a href="research.html">Research</a></li>
        <li><a href="applications.html">Applications</a></li>
        <li><a href="resources.html" class="active">Resources</a></li>
    </ul>
</nav>

<div class="page-body">
<div class="container">

    <section class="hero fade-in">
        <span class="hero-label">Resources</span>
        <h1>Everything you need to <span class="accent">get started</span>.</h1>
        <p class="hero-sub">The paper, the code, the pip package, the sandbox options, and related work worth reading. No filler.</p>
    </section>

    <hr class="divider">

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Primary</span>
                <h2>The paper and code</h2>
            </div>
            <div>
                <p><strong>arXiv Paper</strong><br>
                <a href="https://arxiv.org/abs/2512.24601" target="_blank">arxiv.org/abs/2512.24601</a><br>
                "Recursive Language Models" -- Alex L. Zhang, Tim Kraska, Omar Khattab. MIT OASYS Lab. Accepted at ICML 2025. The full paper with all benchmarks, ablations, and training details.</p>

                <p><strong>HTML Version</strong><br>
                <a href="https://arxiv.org/html/2512.24601v2" target="_blank">arxiv.org/html/2512.24601v2</a><br>
                Readable in-browser version with figures and tables rendered inline.</p>

                <p><strong>GitHub Repository</strong><br>
                <a href="https://github.com/alexzhang13/rlm" target="_blank">github.com/alexzhang13/rlm</a><br>
                The official inference engine. Supports OpenAI, Anthropic, OpenRouter, Portkey, LiteLLM, and vLLM backends. Multiple REPL environments (local, Docker, Modal, Prime Intellect). MIT license.</p>

                <p><strong>Minimal Implementation</strong><br>
                <a href="https://github.com/alexzhang13/rlm-minimal" target="_blank">github.com/alexzhang13/rlm-minimal</a><br>
                Stripped-down reference implementation for understanding the core algorithm without the full library overhead.</p>

                <p><strong>pip Package</strong><br>
                <code>pip install rlms</code><br>
                Install and use in three lines of Python. Supports all major model providers out of the box.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Quick start</span>
                <h2>Running your first RLM</h2>
            </div>
            <div>
                <div style="background: var(--bg-alt, rgba(255,255,255,0.02)); padding: 1.5rem; border-radius: 6px; font-family: monospace; font-size: 0.85rem; border: 1px solid var(--border); line-height: 1.6;">
<pre style="margin:0; color: var(--text);">pip install rlms

from rlm import RLM

rlm = RLM(
    backend="openai",
    backend_kwargs={"model_name": "gpt-5-nano"},
    verbose=True,
)

response = rlm.completion("Your very long prompt here...")
print(response.response)</pre>
                </div>
                <p style="margin-top: 1rem;">That's it. The <code>rlm.completion()</code> call is a drop-in replacement for <code>llm.completion()</code>. Same input (a string prompt), same output (a string response). The recursion happens transparently.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Blogpost</span>
                <h2>Author's blog</h2>
            </div>
            <div>
                <p><strong>Original Blogpost (October 2025)</strong><br>
                <a href="https://alexzhang13.github.io/blog/2025/rlm/" target="_blank">alexzhang13.github.io/blog/2025/rlm/</a><br>
                Alex Zhang's original blog post that introduced the RLM idea before the expanded arXiv paper. Good for intuition-building.</p>

                <p><strong>Documentation</strong><br>
                <a href="https://alexzhang13.github.io/rlm/" target="_blank">alexzhang13.github.io/rlm/</a><br>
                Official documentation for the rlms library. API reference, configuration options, and examples.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Community</span>
                <h2>Discussions and integrations</h2>
            </div>
            <div>
                <p><strong>Google ADK Discussion</strong><br>
                <a href="https://discuss.google.dev/t/recursive-language-models-in-adk/323523" target="_blank">discuss.google.dev/t/recursive-language-models-in-adk/323523</a><br>
                Community discussion on integrating RLMs with Google's Agent Development Kit for long-context agent tasks.</p>

                <p><strong>ArXivIQ Coverage</strong><br>
                <a href="https://arxiviq.substack.com/p/recursive-language-models" target="_blank">arxiviq.substack.com/p/recursive-language-models</a><br>
                Summary and analysis of the RLM paper from the ArXivIQ newsletter.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Related work</span>
                <h2>Papers worth reading alongside RLMs</h2>
            </div>
            <div>
                <p><strong>Inference-time scaling and reasoning:</strong></p>
                <ul>
                    <li>Merrill and Sabharwal (2024) -- "The Expressive Power of Transformers with Chain of Thought." Theoretical foundation for why inference-time compute adds expressive power.</li>
                    <li>DeepSeek-R1 -- Pure RL training for chain-of-thought reasoning, demonstrating that models can learn reasoning strategies without human demonstrations.</li>
                </ul>

                <p><strong>Long-context benchmarks:</strong></p>
                <ul>
                    <li>RULER (Hsieh et al., 2024) -- Needle-in-a-haystack and retrieval benchmarks for long-context evaluation.</li>
                    <li>OOLONG (Bertsch et al., 2025) -- Long reasoning benchmark requiring semantic transformation and aggregation.</li>
                    <li>BrowseComp-Plus (Chen et al., 2025) -- Deep research benchmark over large document corpora.</li>
                    <li>LongBench-v2 (Bai et al., 2025) -- Code repository understanding and other long-context tasks.</li>
                </ul>

                <p><strong>Agent scaffolds and context management:</strong></p>
                <ul>
                    <li>CodeAct (Wang et al., 2024) -- Code execution in a ReAct agent loop.</li>
                    <li>DSPy (Khattab et al., 2021) -- Programmatic framework for LLM pipelines, including context management.</li>
                    <li>Context compaction approaches (Smith 2025, Wu et al. 2025) -- Iterative summarization of agent trajectories.</li>
                </ul>

                <p><strong>Self-delegation:</strong></p>
                <ul>
                    <li>Anthropic sub-agent patterns (2025) -- Autoregressive self-delegation, contrasted with RLMs' programmatic approach.</li>
                    <li>Schroeder et al. (2025), Sun et al. (2025) -- Other approaches to LLM self-invocation.</li>
                </ul>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Citation</span>
                <h2>BibTeX</h2>
            </div>
            <div>
                <div style="background: var(--bg-alt, rgba(255,255,255,0.02)); padding: 1.5rem; border-radius: 6px; font-family: monospace; font-size: 0.8rem; border: 1px solid var(--border); line-height: 1.5;">
<pre style="margin:0; color: var(--text);">@misc{zhang2025recursivelanguagemodels,
    title={Recursive Language Models},
    author={Alex L. Zhang and Tim Kraska and Omar Khattab},
    year={2025},
    eprint={2512.24601},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2512.24601},
}</pre>
                </div>
            </div>
        </div>
    </section>

</div>
</div>

<footer class="site-footer">
    <p>rlm.md -- Built to explain, not to impress. Content updated February 2026.</p>
</footer>

<script>
const obs = new IntersectionObserver((entries) => {
    entries.forEach(e => { if (e.isIntersecting) { e.target.classList.add('visible'); obs.unobserve(e.target); }});
}, { threshold: 0.15 });
document.querySelectorAll('.fade-in').forEach(el => obs.observe(el));
document.querySelectorAll('.nav-links a').forEach(a => {
    a.addEventListener('click', () => document.querySelector('.nav-links').classList.remove('open'));
});
</script>
</body>
</html>
