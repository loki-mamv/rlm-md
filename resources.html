<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Resources -- Papers, Code, and Tools | rlm.md</title>
    <meta name="description" content="Essential resources for Recursive Language Models: the arXiv paper, GitHub repository, pip package, sandbox options, Google ADK integration, and related work on long-context processing.">
    <meta name="keywords" content="RLM resources, recursive language models code, rlms pip package, RLM GitHub, Google ADK RLM, long context papers">
    <link rel="canonical" href="https://rlm.md/resources.html">
    <meta property="og:title" content="Resources -- Papers, Code, and Tools">
    <meta property="og:description" content="Everything you need to start using Recursive Language Models: paper, code, pip package, and related work.">
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 32 32'%3E%3Ctext x='16' y='24' font-family='monospace' font-weight='800' font-size='14' fill='%23c9a84c' text-anchor='middle'%3Erlm%3C/text%3E%3C/svg%3E">
    <link rel="stylesheet" href="style.css">
</head>
<body>

<nav class="site-nav">
    <a href="index.html" class="site-logo">rlm<span class="dot">.md</span></a>
    <button class="nav-toggle" onclick="document.querySelector('.nav-links').classList.toggle('open')" aria-label="Menu">///</button>
    <ul class="nav-links">
        <li><a href="./">Home</a></li>
        <li><a href="fundamentals.html">Fundamentals</a></li>
        <li><a href="techniques.html">Techniques</a></li>
        <li><a href="research.html">Research</a></li>
        <li><a href="rlm-vs-llm.html">RLM vs LLM</a></li>
        <li><a href="applications.html">Applications</a></li>
        <li><a href="resources.html" class="active">Resources</a></li>
        <li><a href="blog/">Blog</a></li>
    </ul>
</nav>

<div class="page-body">
<div class="container">

    <section class="hero fade-in">
        <span class="hero-label">Resources</span>
        <h1>Everything you need to <span class="accent">get started</span>.</h1>
        <p class="hero-sub">The paper, the code, the pip package, the sandbox options, and related work worth reading. No filler.</p>
    </section>

    <hr class="divider">

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Primary</span>
                <h2>The paper and code</h2>
            </div>
            <div>
                <p><strong>arXiv Paper</strong><br>
                <a href="https://arxiv.org/abs/2512.24601" target="_blank">arxiv.org/abs/2512.24601</a><br>
                "Recursive Language Models" -- Alex L. Zhang, Tim Kraska, Omar Khattab. MIT OASYS Lab. Accepted at ICML 2025. The full paper with all benchmarks, ablations, and training details.</p>

                <p><strong>HTML Version</strong><br>
                <a href="https://arxiv.org/html/2512.24601v2" target="_blank">arxiv.org/html/2512.24601v2</a><br>
                Readable in-browser version with figures and tables rendered inline.</p>

                <p><strong>GitHub Repository</strong><br>
                <a href="https://github.com/alexzhang13/rlm" target="_blank">github.com/alexzhang13/rlm</a><br>
                The official inference engine. Supports OpenAI, Anthropic, OpenRouter, Portkey, LiteLLM, and vLLM backends. Multiple REPL environments (local, Docker, Modal, Prime Intellect). MIT license.</p>

                <p><strong>Minimal Implementation</strong><br>
                <a href="https://github.com/alexzhang13/rlm-minimal" target="_blank">github.com/alexzhang13/rlm-minimal</a><br>
                Stripped-down reference implementation for understanding the core algorithm without the full library overhead.</p>

                <p><strong>pip Package</strong><br>
                <code>pip install rlms</code><br>
                Install and use in three lines of Python. Supports all major model providers out of the box.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Quick start</span>
                <h2>Running your first RLM</h2>
            </div>
            <div>
                <div style="background: var(--bg-alt, rgba(255,255,255,0.02)); padding: 1.5rem; border-radius: 6px; font-family: monospace; font-size: 0.85rem; border: 1px solid var(--border); line-height: 1.6;">
<pre style="margin:0; color: var(--text);">pip install rlms

from rlm import RLM

rlm = RLM(
    backend="openai",
    backend_kwargs={"model_name": "gpt-5-nano"},
    verbose=True,
)

response = rlm.completion("Your very long prompt here...")
print(response.response)</pre>
                </div>
                <p style="margin-top: 1rem;">That's it. The <code>rlm.completion()</code> call is a drop-in replacement for <code>llm.completion()</code>. Same input (a string prompt), same output (a string response). The recursion happens transparently.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Blogpost</span>
                <h2>Author's blog</h2>
            </div>
            <div>
                <p><strong>Original Blogpost (October 2025)</strong><br>
                <a href="https://alexzhang13.github.io/blog/2025/rlm/" target="_blank">alexzhang13.github.io/blog/2025/rlm/</a><br>
                Alex Zhang's original blog post that introduced the RLM idea before the expanded arXiv paper. Good for intuition-building.</p>

                <p><strong>Documentation</strong><br>
                <a href="https://alexzhang13.github.io/rlm/" target="_blank">alexzhang13.github.io/rlm/</a><br>
                Official documentation for the rlms library. API reference, configuration options, and examples.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Community</span>
                <h2>Discussions and integrations</h2>
            </div>
            <div>
                <p><strong>Google ADK Discussion</strong><br>
                <a href="https://discuss.google.dev/t/recursive-language-models-in-adk/323523" target="_blank">discuss.google.dev/t/recursive-language-models-in-adk/323523</a><br>
                Community discussion on integrating RLMs with Google's Agent Development Kit for long-context agent tasks.</p>

                <p><strong>ArXivIQ Coverage</strong><br>
                <a href="https://arxiviq.substack.com/p/recursive-language-models" target="_blank">arxiviq.substack.com/p/recursive-language-models</a><br>
                Summary and analysis of the RLM paper from the ArXivIQ newsletter.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Framework support</span>
                <h2>DSPy and Google ADK</h2>
            </div>
            <div>
                <p><strong>DSPy RLM Support (v3.1.2+)</strong><br>
                <a href="https://dspy.ai/" target="_blank">dspy.ai</a><br>
                Stanford's programmatic LLM framework has built-in RLM support. Initialize with <code>dspy.RLM('input -> output')</code> and it handles REPL setup, sub-calls, and aggregation. Supports separate sub-call models via <code>sub_lm</code> parameter.</p>

                <p><strong>Google ADK Implementation (by Liam Connell)</strong><br>
                <a href="https://medium.com/google-cloud/recursive-language-models-in-adk-d9dc736f0478" target="_blank">medium.com/google-cloud/recursive-language-models-in-adk-d9dc736f0478</a><br>
                Enterprise-ready reimplementation using Google's Agent Development Kit. Extends the paper with lazy file loading (GCS, local filesystem) and parallelism for sub-calls. Published January 2026.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Press coverage</span>
                <h2>What people are writing</h2>
            </div>
            <div>
                <p><strong>VentureBeat</strong> -- <a href="https://venturebeat.com/orchestration/mits-new-recursive-framework-lets-llms-process-10-million-tokens-without" target="_blank">"MIT's new 'recursive' framework lets LLMs process 10 million tokens without context rot"</a><br>
                Detailed technical breakdown of the paper with cost analysis and model comparison notes.</p>

                <p><strong>InfoQ</strong> -- <a href="https://www.infoq.com/news/2026/01/mit-recursive-lm/" target="_blank">"MIT's Recursive Language Models Improve Performance on Long-Context Tasks"</a><br>
                Engineering-focused summary, includes Alex Zhang's "bitter-lesson-pilled" framing and the partially observable problem insight.</p>

                <p><strong>Towards Data Science</strong> -- <a href="https://towardsdatascience.com/going-beyond-the-context-window-recursive-language-models-in-action/" target="_blank">"Going Beyond the Context Window: Recursive Language Models in Action"</a><br>
                Practical walkthrough using DSPy's RLM implementation to process 386K tokens of articles with Claude Sonnet 4.5.</p>

                <p><strong>The Neuron</strong> -- <a href="https://www.theneuron.ai/explainer-articles/recursive-language-models-rlms-the-clever-hack-that-gives-ai-infinite-memory/" target="_blank">"Recursive Language Models: The Clever Hack That Gives AI Infinite Memory"</a><br>
                Accessible explainer with the library analogy and key results summary.</p>

                <p><strong>WordLift</strong> -- <a href="https://wordlift.io/blog/en/recursive-language-models-on-kg/" target="_blank">"RLM-on-KG: Recursive Language Models and the Future of SEO"</a><br>
                Explores RLM applications for knowledge graphs and search engine optimization.</p>

                <p><strong>DEV Community</strong> -- <a href="https://dev.to/gaodalie_ai/rlm-the-ultimate-evolution-of-ai-recursive-language-models-3h8o" target="_blank">"RLM: The Ultimate Evolution of AI?"</a><br>
                Developer-oriented overview of the paradigm shift from passive reading to active problem-solving.</p>

                <p><strong>Dextralabs</strong> -- <a href="https://dextralabs.com/blog/recursive-language-models-rlm/" target="_blank">"Why Recursive Language Models Beat Long-Context LLMs"</a><br>
                Enterprise-focused analysis with practical implications for legal, engineering, and data teams.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Related work</span>
                <h2>Papers worth reading alongside RLMs</h2>
            </div>
            <div>
                <p><strong>Inference-time scaling and reasoning:</strong></p>
                <ul>
                    <li>Merrill and Sabharwal (2024) -- "The Expressive Power of Transformers with Chain of Thought." Theoretical foundation for why inference-time compute adds expressive power.</li>
                    <li>DeepSeek-R1 -- Pure RL training for chain-of-thought reasoning, demonstrating that models can learn reasoning strategies without human demonstrations.</li>
                </ul>

                <p><strong>Long-context benchmarks:</strong></p>
                <ul>
                    <li>RULER (Hsieh et al., 2024) -- Needle-in-a-haystack and retrieval benchmarks for long-context evaluation.</li>
                    <li>OOLONG (Bertsch et al., 2025) -- Long reasoning benchmark requiring semantic transformation and aggregation.</li>
                    <li>BrowseComp-Plus (Chen et al., 2025) -- Deep research benchmark over large document corpora.</li>
                    <li>LongBench-v2 (Bai et al., 2025) -- Code repository understanding and other long-context tasks.</li>
                </ul>

                <p><strong>Agent scaffolds and context management:</strong></p>
                <ul>
                    <li>CodeAct (Wang et al., 2024) -- Code execution in a ReAct agent loop.</li>
                    <li>DSPy (Khattab et al., 2021) -- Programmatic framework for LLM pipelines, including context management.</li>
                    <li>Context compaction approaches (Smith 2025, Wu et al. 2025) -- Iterative summarization of agent trajectories.</li>
                </ul>

                <p><strong>Self-delegation:</strong></p>
                <ul>
                    <li>Anthropic sub-agent patterns (2025) -- Autoregressive self-delegation, contrasted with RLMs' programmatic approach.</li>
                    <li>Schroeder et al. (2025), Sun et al. (2025) -- Other approaches to LLM self-invocation.</li>
                </ul>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">Citation</span>
                <h2>BibTeX</h2>
            </div>
            <div>
                <div style="background: var(--bg-alt, rgba(255,255,255,0.02)); padding: 1.5rem; border-radius: 6px; font-family: monospace; font-size: 0.8rem; border: 1px solid var(--border); line-height: 1.5;">
<pre style="margin:0; color: var(--text);">@misc{zhang2025recursivelanguagemodels,
    title={Recursive Language Models},
    author={Alex L. Zhang and Tim Kraska and Omar Khattab},
    year={2025},
    eprint={2512.24601},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2512.24601},
}</pre>
                </div>
            </div>
        </div>
    </section>

</div>
</div>

<footer class="site-footer">
    <p>rlm.md -- Built to explain, not to impress. Content updated February 2026.</p>
</footer>

<script>
const obs = new IntersectionObserver((entries) => {
    entries.forEach(e => { if (e.isIntersecting) { e.target.classList.add('visible'); obs.unobserve(e.target); }});
}, { threshold: 0.15 });
document.querySelectorAll('.fade-in').forEach(el => obs.observe(el));
document.querySelectorAll('.nav-links a').forEach(a => {
    a.addEventListener('click', () => document.querySelector('.nav-links').classList.remove('open'));
});
</script>
</body>
</html>
