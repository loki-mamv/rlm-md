<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>rlm.md -- Recursive Language Models</title>
    <meta name="description" content="Recursive Language Models (RLMs) let LLMs process arbitrarily long inputs by treating the prompt as an external environment and recursively calling themselves over snippets. From the MIT OASYS lab.">
    <meta name="keywords" content="recursive language models, RLM, long context, inference-time scaling, RLM-Qwen3-8B, GPT-5, context window, REPL, decompose recurse aggregate">
    <link rel="canonical" href="https://rlm.md/">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://rlm.md/">
    <meta property="og:title" content="rlm.md -- Recursive Language Models">
    <meta property="og:description" content="How RLMs let language models process inputs 100x beyond their context windows by recursively calling themselves over snippets.">
    <meta property="og:site_name" content="rlm.md">
    <meta property="og:image" content="https://rlm.md/og-image.jpg">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="rlm.md -- Recursive Language Models">
    <meta name="twitter:description" content="The inference paradigm that makes context windows irrelevant.">
    <meta name="twitter:image" content="https://rlm.md/og-image.jpg">
    <script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","url":"https://rlm.md","name":"rlm.md","description":"Recursive Language Models: how LLMs process arbitrarily long inputs by treating prompts as external environments and recursively self-calling over snippets."}</script>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 32 32'%3E%3Ctext x='16' y='24' font-family='monospace' font-weight='800' font-size='14' fill='%23c9a84c' text-anchor='middle'%3Erlm%3C/text%3E%3C/svg%3E">
    <link rel="stylesheet" href="style.css">
</head>
<body>

<nav class="site-nav">
    <a href="index.html" class="site-logo">rlm<span class="dot">.md</span></a>
    <button class="nav-toggle" onclick="document.querySelector('.nav-links').classList.toggle('open')" aria-label="Menu">///</button>
    <ul class="nav-links">
        <li><a href="./" class="active">Home</a></li>
        <li><a href="fundamentals.html">Fundamentals</a></li>
        <li><a href="techniques.html">Techniques</a></li>
        <li><a href="research.html">Research</a></li>
        <li><a href="rlm-vs-llm.html">RLM vs LLM</a></li>
        <li><a href="applications.html">Applications</a></li>
        <li><a href="resources.html">Resources</a></li>
        <li><a href="blog/">Blog</a></li>
    </ul>
</nav>

<div class="page-body">
<div class="container">

    <section class="hero fade-in">
        <span class="hero-label">Recursive Language Models</span>
        <h1>Stop cramming. <span class="accent">Start recursing.</span></h1>
        <p class="hero-sub">Context windows are a leash. Every LLM has one, and every LLM eventually chokes on it. Recursive Language Models cut the leash entirely -- they let a model process inputs two orders of magnitude beyond its context window by treating the prompt as an external environment and recursively calling itself over snippets.</p>
        <p class="hero-sub" style="color: var(--text-dim); font-size: 0.9rem;">RLMs come from the <a href="https://arxiv.org/abs/2512.24601" target="_blank">MIT OASYS lab</a> (Zhang, Kraska, Khattab). An 8B model post-trained with this approach outperforms vanilla GPT-5 on long-context tasks. Start with <a href="fundamentals.html">how it works</a>, or see <a href="research.html">the benchmark results</a>.</p>
    </section>

    <hr class="divider">

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">The problem</span>
                <h2>Context windows are a lie</h2>
            </div>
            <div>
                <p>GPT-5 advertises a 272K token context window. Sounds generous. But feed it a task that requires dense reasoning over all 272K tokens -- not just finding a needle, but actually processing every line -- and performance falls off a cliff. This is called <strong>context rot</strong>, and every model suffers from it.</p>
                <p>The industry response has been to make windows bigger. 1M tokens. 10M tokens. But bigger windows don't solve the fundamental issue: Transformers degrade on long, information-dense inputs regardless of what fits technically.</p>
                <p>RLMs take a different approach. Instead of forcing the entire prompt through the neural network at once, they let the model <strong>programmatically examine, decompose, and recursively call itself</strong> over pieces of the input. The prompt lives in a REPL environment as a variable. The model writes code to slice it, process the slices, and aggregate results.</p>
                <p>The result: effective processing of 10M+ token inputs. Not with summarization hacks or retrieval tricks. With actual dense semantic work across the entire input.</p>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <span class="split-label">The key difference</span>
        <h2>LLM vs RLM</h2>
        <p style="color: var(--text-muted); margin-bottom: 2.5rem; max-width: 50ch;">Two fundamentally different approaches to processing long inputs. <a href="rlm-vs-llm.html">Read the full comparison →</a></p>

        <div class="arch-compare">
            <div class="arch-col">
                <div class="arch-label">Large Language Model</div>
                <div class="arch-diagram">
                    <svg viewBox="0 0 280 320" fill="none" xmlns="http://www.w3.org/2000/svg" class="arch-svg">
                        <!-- Input block -->
                        <rect x="40" y="10" width="200" height="44" rx="6" fill="#16161f" stroke="#2a2a3a" stroke-width="1"/>
                        <text x="140" y="28" text-anchor="middle" fill="#8a8698" font-size="10" font-family="Space Grotesk">272K tokens</text>
                        <text x="140" y="42" text-anchor="middle" fill="#5a5668" font-size="9" font-family="JetBrains Mono">entire input</text>
                        <!-- Arrow down -->
                        <line x1="140" y1="54" x2="140" y2="90" stroke="#5a5668" stroke-width="1" stroke-dasharray="4,3"/>
                        <polygon points="135,88 140,96 145,88" fill="#5a5668"/>
                        <!-- Model block (single) -->
                        <rect x="50" y="98" width="180" height="80" rx="8" fill="#16161f" stroke="#b05a6a" stroke-width="1.5" stroke-opacity="0.6"/>
                        <text x="140" y="130" text-anchor="middle" fill="#e0dcd4" font-size="12" font-family="Space Grotesk" font-weight="600">LLM</text>
                        <text x="140" y="148" text-anchor="middle" fill="#b05a6a" font-size="9" font-family="JetBrains Mono">single forward pass</text>
                        <text x="140" y="164" text-anchor="middle" fill="#5a5668" font-size="8" font-family="JetBrains Mono">attention over ALL tokens</text>
                        <!-- Arrow down -->
                        <line x1="140" y1="178" x2="140" y2="214" stroke="#5a5668" stroke-width="1" stroke-dasharray="4,3"/>
                        <polygon points="135,212 140,220 145,212" fill="#5a5668"/>
                        <!-- Warning -->
                        <text x="200" y="200" fill="#b05a6a" font-size="9" font-family="JetBrains Mono" opacity="0.8">⚠ degrades</text>
                        <!-- Output block -->
                        <rect x="60" y="222" width="160" height="40" rx="6" fill="#16161f" stroke="#b05a6a" stroke-width="1" stroke-opacity="0.4"/>
                        <text x="140" y="246" text-anchor="middle" fill="#8a8698" font-size="10" font-family="Space Grotesk">Output</text>
                        <!-- Quality indicator -->
                        <rect x="70" y="272" width="140" height="6" rx="3" fill="#1a1a24"/>
                        <rect x="70" y="272" width="50" height="6" rx="3" fill="#b05a6a" opacity="0.7"/>
                        <text x="140" y="292" text-anchor="middle" fill="#5a5668" font-size="8" font-family="JetBrains Mono">quality on long inputs</text>
                    </svg>
                </div>
            </div>
            <div class="arch-col arch-col--accent">
                <div class="arch-label">Recursive Language Model</div>
                <div class="arch-diagram">
                    <svg viewBox="0 0 280 320" fill="none" xmlns="http://www.w3.org/2000/svg" class="arch-svg">
                        <!-- Input block -->
                        <rect x="40" y="10" width="200" height="44" rx="6" fill="#16161f" stroke="#2a2a3a" stroke-width="1"/>
                        <text x="140" y="28" text-anchor="middle" fill="#8a8698" font-size="10" font-family="Space Grotesk">10M+ tokens</text>
                        <text x="140" y="42" text-anchor="middle" fill="#5a5668" font-size="9" font-family="JetBrains Mono">stored as env variable</text>
                        <!-- Decompose arrow -->
                        <line x1="140" y1="54" x2="140" y2="70" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.6"/>
                        <!-- Fan out lines -->
                        <line x1="140" y1="70" x2="55" y2="90" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.4"/>
                        <line x1="140" y1="70" x2="140" y2="90" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.4"/>
                        <line x1="140" y1="70" x2="225" y2="90" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.4"/>
                        <!-- Chunk label -->
                        <text x="140" y="82" text-anchor="middle" fill="#c9a84c" font-size="8" font-family="JetBrains Mono" opacity="0.8">decompose</text>
                        <!-- Model chunks -->
                        <rect x="20" y="94" width="70" height="50" rx="5" fill="#16161f" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.5"/>
                        <text x="55" y="116" text-anchor="middle" fill="#c9a84c" font-size="9" font-family="JetBrains Mono">LLM</text>
                        <text x="55" y="130" text-anchor="middle" fill="#5a5668" font-size="7" font-family="JetBrains Mono">chunk 1</text>
                        <rect x="105" y="94" width="70" height="50" rx="5" fill="#16161f" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.5"/>
                        <text x="140" y="116" text-anchor="middle" fill="#c9a84c" font-size="9" font-family="JetBrains Mono">LLM</text>
                        <text x="140" y="130" text-anchor="middle" fill="#5a5668" font-size="7" font-family="JetBrains Mono">chunk 2</text>
                        <rect x="190" y="94" width="70" height="50" rx="5" fill="#16161f" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.5"/>
                        <text x="225" y="116" text-anchor="middle" fill="#c9a84c" font-size="9" font-family="JetBrains Mono">LLM</text>
                        <text x="225" y="130" text-anchor="middle" fill="#5a5668" font-size="7" font-family="JetBrains Mono">chunk N</text>
                        <!-- Recurse arrows (loop) -->
                        <path d="M 265 110 C 275 110, 275 130, 265 130" stroke="#4a9ead" stroke-width="1" fill="none" stroke-opacity="0.5"/>
                        <polygon points="264,128 267,134 270,128" fill="#4a9ead" opacity="0.5"/>
                        <text x="268" y="155" fill="#4a9ead" font-size="7" font-family="JetBrains Mono" opacity="0.7">recurse</text>
                        <!-- Fan in lines -->
                        <line x1="55" y1="144" x2="140" y2="174" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.4"/>
                        <line x1="140" y1="144" x2="140" y2="174" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.4"/>
                        <line x1="225" y1="144" x2="140" y2="174" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.4"/>
                        <!-- Aggregate label -->
                        <text x="140" y="168" text-anchor="middle" fill="#c9a84c" font-size="8" font-family="JetBrains Mono" opacity="0.8">aggregate</text>
                        <!-- Aggregate block -->
                        <rect x="60" y="178" width="160" height="44" rx="6" fill="#16161f" stroke="#4a9ead" stroke-width="1.5" stroke-opacity="0.6"/>
                        <text x="140" y="196" text-anchor="middle" fill="#e0dcd4" font-size="10" font-family="Space Grotesk" font-weight="600">REPL Environment</text>
                        <text x="140" y="212" text-anchor="middle" fill="#4a9ead" font-size="8" font-family="JetBrains Mono">merge partial results</text>
                        <!-- Arrow down -->
                        <line x1="140" y1="222" x2="140" y2="248" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.6"/>
                        <polygon points="135,246 140,254 145,246" fill="#c9a84c" opacity="0.6"/>
                        <!-- Output block -->
                        <rect x="60" y="256" width="160" height="40" rx="6" fill="#16161f" stroke="#c9a84c" stroke-width="1" stroke-opacity="0.6"/>
                        <text x="140" y="280" text-anchor="middle" fill="#c9a84c" font-size="10" font-family="Space Grotesk" font-weight="500">Output</text>
                        <!-- Quality indicator -->
                        <rect x="70" y="306" width="140" height="6" rx="3" fill="#1a1a24"/>
                        <rect x="70" y="306" width="130" height="6" rx="3" fill="#c9a84c" opacity="0.7"/>
                        <text x="140" y="320" text-anchor="middle" fill="#5a5668" font-size="8" font-family="JetBrains Mono">quality on long inputs</text>
                    </svg>
                </div>
            </div>
        </div>
    </section>

    <section class="section fade-in">
        <span class="split-label">Start here</span>
        <h2>The complete picture, in five parts.</h2>
        <div class="card-grid stagger" style="margin-top: 2rem;">
            <a href="fundamentals.html" class="card" style="--i:0; text-decoration:none; border-bottom:none;">
                <div class="card-number">01</div>
                <h3>Fundamentals</h3>
                <p>The decompose-recurse-aggregate pattern. How prompts become environment variables. Why symbolic recursion changes everything.</p>
            </a>
            <a href="techniques.html" class="card" style="--i:1; text-decoration:none; border-bottom:none;">
                <div class="card-number">02</div>
                <h3>Techniques</h3>
                <p>Programmatic examination, decomposition strategies, REPL environments, sub-call patterns. How RLM-Qwen3-8B was post-trained. RLMs vs RAG vs sliding window.</p>
            </a>
            <a href="research.html" class="card" style="--i:2; text-decoration:none; border-bottom:none;">
                <div class="card-number">03</div>
                <h3>Research</h3>
                <p>The arXiv paper dissected. Benchmark results across S-NIAH, OOLONG, BrowseComp-Plus, and CodeQA. RLM-Qwen3-8B vs GPT-5, head to head.</p>
            </a>
        </div>
        <div class="card-grid stagger" style="margin-top: 1.5rem;">
            <a href="applications.html" class="card" style="--i:3; text-decoration:none; border-bottom:none;">
                <div class="card-number">04</div>
                <h3>Applications</h3>
                <p>Where RLMs change the game: book-length analysis, legal document processing, codebase understanding, deep research over massive corpora.</p>
            </a>
            <a href="resources.html" class="card" style="--i:4; text-decoration:none; border-bottom:none;">
                <div class="card-number">05</div>
                <h3>Resources</h3>
                <p>The paper, the GitHub repo, the pip package, sandbox options, Google ADK integration, and related work on long-context processing.</p>
            </a>
        </div>
    </section>

    <section class="section fade-in">
        <div class="split">
            <div>
                <span class="split-label">The headline numbers</span>
                <h2>This isn't theoretical</h2>
            </div>
            <div>
                <p>RLM-Qwen3-8B -- an 8-billion parameter model post-trained on just 1,000 samples -- outperforms the base Qwen3-8B by <strong>28.3% on average</strong> across four diverse long-context benchmarks. It approaches the quality of vanilla GPT-5 on three of them.</p>
                <p>At the frontier scale, RLM(GPT-5) maintains strong performance on inputs up to 2^18 tokens (262K+), while vanilla GPT-5 degrades sharply as inputs grow. On OOLONG-Pairs -- a task requiring quadratic-complexity reasoning -- GPT-5 scores less than 0.1% F1. The RLM version scores 58%.</p>
                <p>The cost? Comparable. At the median, RLM runs are actually <em>cheaper</em> than base model calls on GPT-5, because the model selectively examines context rather than ingesting everything at once.</p>
                <p>The ecosystem is already moving. DSPy (v3.1.2+) ships with built-in RLM support. Google's Agent Development Kit has an enterprise-ready implementation with lazy file loading and parallel sub-calls. VentureBeat, InfoQ, and Towards Data Science have all published deep dives in the last month. This isn't a paper that got filed away -- it's being adopted.</p>
                <div class="callout" style="margin-top:2rem;">
                    <p>"It's a partially observable problem that you're giving the LM, where it can make logical decisions based on the structure of the task and context." -- Alex Zhang, MIT CSAIL</p>
                </div>
            </div>
        </div>
    </section>

</div>
</div>

<footer class="site-footer">
    <p>rlm.md -- Built to explain, not to impress. Content updated February 2026.</p>
</footer>

<script>
const obs = new IntersectionObserver((entries) => {
    entries.forEach(e => { if (e.isIntersecting) { e.target.classList.add('visible'); obs.unobserve(e.target); }});
}, { threshold: 0.15 });
document.querySelectorAll('.fade-in').forEach(el => obs.observe(el));
document.querySelectorAll('.nav-links a').forEach(a => {
    a.addEventListener('click', () => document.querySelector('.nav-links').classList.remove('open'));
});
</script>
</body>
</html>
